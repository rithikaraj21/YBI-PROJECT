from transformers import GPT2Tokenizer, GPT2LMHeadModel
import torch

# Load pre-trained model and tokenizer
model_name = "gpt2"  # You can also try "gpt2-medium", "distilgpt2", etc.
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# Set model to evaluation mode
model.eval()

# Input prompt
prompt = "Once upon a time in a distant land"

# Encode the input text to tensor
input_ids = tokenizer.encode(prompt, return_tensors="pt")

# Generate text from the input
output = model.generate(
    input_ids,
    max_length=100,       # Total number of tokens (input + generated)
    num_return_sequences=1,
    no_repeat_ngram_size=2,
    temperature=0.7,
    top_k=50,
    top_p=0.95,
    do_sample=True,
    early_stopping=True
)

# Decode the output tensor to text
generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

print("Generated Text:\n")
print(generated_text)
